# import streamlit as st
# from PIL import Image, ImageDraw
# import torch
# import torchvision.transforms as T
# import torch.nn as nn
# from torchvision import models
# import numpy as np
# import joblib
# from numpy.linalg import norm

# # Import h√†m load_model c·ªßa b·∫°n (Faster R-CNN)
# from main_script import load_model

# # ======================================================
# # CONFIG
# # ======================================================
# FASTER_MODEL_PATH = 'fasterrcnn_phone_defect.pth'
# RF_MODEL_PATH = 'randomforest_best.pkl'
# SCALER_PATH = 'scaler.pkl'
# THRESHOLD = 0.75  # cosine similarity threshold for phone detection

# # ======================================================
# # LOAD MODELS (CACHED)
# # ======================================================
# @st.cache_resource
# def get_faster_model():
#     model = load_model(FASTER_MODEL_PATH)
#     device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
#     model.to(device)
#     print("‚úÖ Faster R-CNN model loaded.")
#     return model, device

# @st.cache_resource
# def get_rf_model():
#     rf = joblib.load(RF_MODEL_PATH)
#     scaler = joblib.load(SCALER_PATH)
#     print("‚úÖ Random Forest model loaded.")
#     return rf, scaler

# # ======================================================
# # FEATURE EXTRACTOR for RF
# # ======================================================
# @st.cache_resource
# def get_feature_extractor():
#     device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
#     resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)
#     feature_extractor = nn.Sequential(*list(resnet.children())[:-1])
#     feature_extractor = feature_extractor.to(device)
#     feature_extractor.eval()

#     transform = T.Compose([
#         T.Resize((224, 224)),
#         T.ToTensor(),
#         T.Normalize(mean=[0.485, 0.456, 0.406],
#                     std=[0.229, 0.224, 0.225]),
#     ])
#     return feature_extractor, transform, device

# def extract_feature(image_pil, feature_extractor, transform, device):
#     img = transform(image_pil).unsqueeze(0).to(device)
#     with torch.no_grad():
#         feat = feature_extractor(img)
#     return feat.cpu().numpy().flatten()

# # ======================================================
# # FASTER R-CNN PREDICT
# # ======================================================
# def predict_faster(model, device, image_pil, score_thresh=0.8):
#     transform = T.ToTensor()
#     img_tensor = transform(image_pil).unsqueeze(0).to(device)

#     with torch.no_grad():
#         outputs = model(img_tensor)[0]
    
#     draw = ImageDraw.Draw(image_pil.copy())
#     label_map = {1: "KH√îNG V·ª†", 2: "V·ª†"}
#     is_defective, detected_object = False, False

#     for box, score, label in zip(outputs["boxes"], outputs["scores"], outputs["labels"]):
#         if score > score_thresh:
#             detected_object = True
#             box = box.cpu().numpy()
#             label_id = label.cpu().item()

#             if label_id == 2:
#                 is_defective = True

#             color = "lime" if label_id == 1 else "red"
#             draw.rectangle([(box[0], box[1]), (box[2], box[3])],
#                            outline=color, width=3)
#             text = f"{label_map[label_id]} ({score:.2f})"
#             draw.text((box[0], max(0, box[1] - 20)), text, fill="yellow")

#     if not detected_object:
#         return "KH√îNG T√åM TH·∫§Y", image_pil
#     elif is_defective:
#         return "V·ª†", image_pil
#     else:
#         return "KH√îNG V·ª†", image_pil

# # ======================================================
# # RANDOM FOREST PREDICT
# # ======================================================
# def predict_random_forest(rf, scaler, feature_extractor, transform, device, image_pil):
#     vec = extract_feature(image_pil, feature_extractor, transform, device)
#     vec_scaled = scaler.transform([vec])
#     pred = rf.predict(vec_scaled)[0]
#     prob = rf.predict_proba(vec_scaled)[0]

#     label_map = {0: "Non-Defective", 1: "Defective"}
#     return label_map[pred], prob[pred] * 100

# # ======================================================
# # STREAMLIT UI
# # ======================================================
# st.set_page_config(layout="wide", page_title="Phone Defect Detection (Dual Model)")

# st.title("üì± Phone Defect Detection Web App")
# st.write("·ª®ng d·ª•ng k·∫øt h·ª£p **Faster R-CNN** v√† **Random Forest** ƒë·ªÉ ph√°t hi·ªán l·ªói m√†n h√¨nh ƒëi·ªán tho·∫°i.")

# col1, col2 = st.columns(2)

# # Load all models
# faster_model, device = get_faster_model()
# rf_model, scaler = get_rf_model()
# feature_extractor, transform, _ = get_feature_extractor()

# with col1:
#     uploaded_file = st.file_uploader("üì§ T·∫£i l√™n ·∫£nh", type=["jpg", "jpeg", "png"])

# with col2:
#     if uploaded_file is not None:
#         image = Image.open(uploaded_file).convert("RGB")
#         st.image(image, caption="·∫¢nh g·ªëc", use_container_width=True)

#         with st.spinner("üîç ƒêang d·ª± ƒëo√°n..."):
#             # Faster R-CNN
#             status, faster_image = predict_faster(faster_model, device, image.copy())

#             # Random Forest
#             rf_label, rf_conf = predict_random_forest(
#                 rf_model, scaler, feature_extractor, transform, device, image.copy()
#             )

#         st.markdown("### üîé K·∫øt qu·∫£ d·ª± ƒëo√°n:")
#         col_a, col_b = st.columns(2)

#         with col_a:
#             st.subheader("**Faster R-CNN**")
#             if status == "V·ª†":
#                 st.error("‚ùå Ph√°t hi·ªán: **V·ª†**")
#             elif status == "KH√îNG V·ª†":
#                 st.success("‚úÖ Ph√°t hi·ªán: **KH√îNG V·ª†**")
#             else:
#                 st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y ƒëi·ªán tho·∫°i.")
#             st.image(faster_image, use_container_width=True)

#         with col_b:
#             st.subheader("**Random Forest**")
#             color = "red" if rf_label == "Defective" else "green"
#             st.markdown(f"<h4 style='color:{color}'>K·∫øt qu·∫£: {rf_label}</h4>", unsafe_allow_html=True)
#             st.write(f"ƒê·ªô tin c·∫≠y: **{rf_conf:.2f}%**")


import streamlit as st
from PIL import Image, ImageDraw, ImageFont
import torch
import torchvision.transforms as T
import numpy as np
import matplotlib.pyplot as plt

# Import h√†m load_model t·ª´ script g·ªëc c·ªßa b·∫°n
from main_script import load_model 

# --- T·ªëi ∆∞u h√≥a: T·∫£i m√¥ h√¨nh m·ªôt l·∫ßn duy nh·∫•t ---
@st.cache_resource
def get_model():
    model_path = 'fasterrcnn_phone_defect.pth' # ƒê·∫£m b·∫£o file model ·ªü c√πng th∆∞ m·ª•c
    model = load_model(model_path)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)
    print("‚úÖ Model loaded and cached.")
    return model, device

# --- H√†m d·ª± ƒëo√°n cho Web App (ƒê√£ c·∫≠p nh·∫≠t logic tr·∫£ v·ªÅ) ---
def predict_for_webapp(model, device, image_pil, score_thresh=0.8):
    """
    H√†m n√†y nh·∫≠n ·∫£nh PIL, d·ª± ƒëo√°n v√† tr·∫£ v·ªÅ:
    - detection_status: M·ªôt chu·ªói ("V·ª†", "KH√îNG V·ª†", "KH√îNG T√åM TH·∫§Y").
    - result_image_pil: ·∫¢nh PIL ƒë√£ v·∫Ω khung.
    """
    transform = T.ToTensor()
    img_tensor = transform(image_pil).unsqueeze(0).to(device)

    with torch.no_grad():
        outputs = model(img_tensor)[0]
    
    image_with_boxes = image_pil.copy() 
    draw = ImageDraw.Draw(image_with_boxes)
    label_map = {1: "KH√îNG V·ª†", 2: "V·ª†"}
    
    is_defective = False
    detected_object = False # Th√™m c·ªù ƒë·ªÉ ki·ªÉm tra c√≥ ph√°t hi·ªán ƒë·ªëi t∆∞·ª£ng n√†o kh√¥ng

    for box, score, label in zip(outputs["boxes"], outputs["scores"], outputs["labels"]):
        if score > score_thresh:
            detected_object = True # N·∫øu c√≥ √≠t nh·∫•t 1 ƒë·ªëi t∆∞·ª£ng, ƒë·∫∑t c·ªù l√† True
            box = box.cpu().numpy()
            label_id = label.cpu().numpy().item()
            
            if label_id == 2: 
                is_defective = True
            
            color = "lime" if label_id == 1 else "red"
            draw.rectangle([(box[0], box[1]), (box[2], box[3])], outline=color, width=3)
            
            text = f"{label_map.get(label_id, 'N/A')}: {score:.2f}"
            
            text_x = box[0]
            text_y = max(0, box[1] - 20)
            bbox = draw.textbbox((text_x, text_y), text)
            draw.rectangle(bbox, fill="black")
            draw.text((text_x, text_y), text, fill="yellow")

    # --- LOGIC TR·∫¢ V·ªÄ M·ªöI ---
    if not detected_object:
        return "KH√îNG T√åM TH·∫§Y", image_pil # Tr·∫£ v·ªÅ ·∫£nh g·ªëc n·∫øu kh√¥ng t√¨m th·∫•y g√¨
    elif is_defective:
        return "V·ª†", image_with_boxes
    else:
        return "KH√îNG V·ª†", image_with_boxes

# --- B·∫Øt ƒë·∫ßu x√¢y d·ª±ng giao di·ªán (ƒê√£ c·∫≠p nh·∫≠t logic hi·ªÉn th·ªã) ---
st.set_page_config(layout="wide", page_title="Phone Defect Detection")

st.title("·ª®ng d·ª•ng Ph√°t hi·ªán L·ªói M√†n h√¨nh ƒêi·ªán tho·∫°i")
st.write("T·∫£i l√™n m·ªôt ·∫£nh ƒëi·ªán tho·∫°i ƒë·ªÉ m√¥ h√¨nh d·ª± ƒëo√°n c√°c v·∫øt n·ª©t, v·ª°.")

model, device = get_model()

col1, col2 = st.columns(2)

with col1:
    uploaded_file = st.file_uploader("Ch·ªçn m·ªôt ·∫£nh", type=["jpg", "jpeg", "png"])

with col2:
    st.write("### K·∫øt qu·∫£ d·ª± ƒëo√°n")
    if uploaded_file is not None:
        image = Image.open(uploaded_file).convert("RGB")
        with st.spinner('ƒêang x·ª≠ l√Ω...'):
            # Ch·∫°y d·ª± ƒëo√°n v√† nh·∫≠n tr·∫°ng th√°i
            detection_status, result_image = predict_for_webapp(model, device, image, score_thresh=0.8)
            
            # --- LOGIC HI·ªÇN TH·ªä M·ªöI ---
            if detection_status == "V·ª†":
                st.error("‚ùå **K·∫æT QU·∫¢:\nFaster R-CNN: PH√ÅT HI·ªÜN V·ª†**")
                st.image(result_image, caption="·∫¢nh K·∫øt Qu·∫£", use_container_width=True)
            
            elif detection_status == "KH√îNG V·ª†":
                st.success("‚úÖ **K·∫æT QU·∫¢:\nFaster R-CNN: KH√îNG V·ª†**")
                st.image(result_image, caption="·∫¢nh K·∫øt Qu·∫£", use_container_width=True)
            
            else: # Tr∆∞·ªùng h·ª£p "KH√îNG T√åM TH·∫§Y"
                st.warning("‚ö†Ô∏è **Kh√¥ng ph√°t hi·ªán th·∫•y ƒëi·ªán tho·∫°i trong ·∫£nh.**")
                st.write("Vui l√≤ng th·ª≠ l·∫°i v·ªõi m·ªôt ·∫£nh kh√°c r√µ r√†ng h∆°n ho·∫∑c ƒë·∫£m b·∫£o ·∫£nh c√≥ ch·ª©a ƒëi·ªán tho·∫°i.")
                st.image(result_image, caption="·∫¢nh ƒë√£ t·∫£i l√™n", use_container_width=True)
    else:
        st.info("H√£y t·∫£i m·ªôt ·∫£nh l√™n ƒë·ªÉ xem k·∫øt qu·∫£.")
#     else:
#         st.info("H√£y t·∫£i l√™n m·ªôt ·∫£nh ƒë·ªÉ b·∫Øt ƒë·∫ßu d·ª± ƒëo√°n.")
